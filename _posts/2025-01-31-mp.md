---
title: "文件筛选2.0"
subtitle: "打造智能重复文件清理器：Python 实战指南"
layout: post
author: "Road"
header-style: text
tags:
  - python
  - 多线程
---

前言
-----

在日常的文件管理中，我们常常会遇到重复文件占用大量磁盘空间的问题。手动查找和清理这些重复文件既耗时又费力。借助 Python 的强大功能，我们可以轻松实现一个智能重复文件清理器，自动帮我们完成这项繁琐的任务。

代码运行环境要求
-----
在运行这份代码之前，需要确保你的开发环境满足以下条件：

- Python 版本：建议使用 Python 3.6 及以上版本，因为代码中使用了一些较新的语法和特性，以提升代码的可读性和性能。例如，在处理日期和时间时，datetime模块的一些新方法让代码更加简洁直观。

- 第三方库：

1. tkinter：这是 Python 的标准 GUI 库，通常随 Python 安装包一同安装。它为我们提供了创建图形化界面的各种组件，如按钮、标签、文本框等，是构建用户交互界面的基础。

2. ttk：是tkinter的主题化扩展，提供了更美观、现代的界面风格。它基于tkinter，但增强了界面的视觉效果，使应用程序看起来更加专业。

3. filedialog：也是tkinter库的一部分，用于实现文件选择对话框，方便用户指定要清理的文件夹路径。

4. messagebox：同样属于tkinter，用于显示各种类型的消息框，如提示框、警告框、错误框等，帮助用户及时了解程序的运行状态和处理结果。

5. csv：Python 内置的用于处理 CSV 文件的库，无需额外安装。在生成文件详情报告时，使用该库将文件信息写入 CSV 文件，方便用户查看和分析。

6. logging：Python 标准库中的日志记录模块，用于记录程序运行过程中的各种信息，如调试信息、错误信息等。通过合理配置日志，我们可以更方便地追踪程序的执行流程和排查问题。

7. threading：Python 的标准线程库，用于实现多线程编程。在处理大量文件时，多线程可以显著提高处理效率，避免主线程阻塞，确保用户界面的响应性。

8. queue：提供了线程安全的队列实现，用于在多线程环境中进行数据传递和同步。在我们的程序中，message_queue用于主线程和处理线程之间传递消息，协调两者的工作。

9. hashlib：Python 标准库中的加密哈希模块，用于计算文件的哈希值。我们使用其中的sha256算法为每个文件生成唯一的哈希标识，以此判断文件是否重复。

10. shutil：提供了一些高级的文件操作功能，如文件复制、移动等。在将重复文件移动到指定文件夹时，使用shutil.move方法确保文件操作的安全和便捷。





核心功能与实现思路
-----


我们的目标是创建一个图形化界面（GUI）应用程序，它能够在指定文件夹及其子文件夹中递归地查找重复文件，并将这些重复文件移动到一个专门的文件夹中，同时生成详细的文件详情报告，包括文件名、文件大小、哈希值和文件路径等信息。

实现这个功能的关键在于计算文件的哈希值。通过计算每个文件的哈希值，我们可以准确地判断文件内容是否相同，即使文件名不同。对于哈希值相同的文件，我们认为它们是重复文件，并将其移动到指定的 “重复文件” 文件夹中。


代码实现与解析
-----

全局配置与日志设置

'''
# ==================== 全局配置 ====================
VALID_EXTENSIONS = ['.jpg', '.png', '.pdf', '.docx']
LOG_FORMAT = '%(asctime)s - %(levelname)s - %(message)s'
PROGRESS_INTERVAL = 100

# ==================== 日志配置 ====================
logging.basicConfig(
    filename='file_cleaner.log',
    level=logging.INFO,
    format=LOG_FORMAT,
    encoding='utf-8'
)
'''


界面设计与交互逻辑
-----

'''
class FileCleanerApp:
    def __init__(self, root):
        self.root = root
        self.root.title("智能重复文件清理器")
        self.root.geometry("800x600")

        # 多线程控制
        self.stop_event = threading.Event()
        self.message_queue = queue.Queue()

        # 初始化界面
        self.create_widgets()
        self.running = False

        # 启动消息处理循环
        self.root.after(100, self.process_messages)

    def create_widgets(self):
        # 顶部控制栏
        control_frame = ttk.Frame(self.root, padding=10)
        control_frame.pack(fill=tk.X)

        self.btn_select = ttk.Button(
            control_frame,
            text="选择文件夹",
            command=self.select_folder,
            state=tk.NORMAL
        )
        self.btn_select.pack(side=tk.LEFT, padx=5)

        self.btn_stop = ttk.Button(
            control_frame,
            text="停止处理",
            command=self.stop_processing,
            state=tk.DISABLED
        )
        self.btn_stop.pack(side=tk.LEFT, padx=5)

        # 进度条
        self.progress = ttk.Progressbar(
            self.root,
            orient=tk.HORIZONTAL,
            mode='determinate'
        )
        self.progress.pack(fill=tk.X, padx=10, pady=5)

        # 实时信息面板
        info_frame = ttk.LabelFrame(self.root, text="处理状态", padding=10)
        info_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

        self.lbl_status = ttk.Label(info_frame, text="就绪")
        self.lbl_status.pack(anchor=tk.W)

        self.lbl_current_file = ttk.Label(info_frame, text="当前文件：无")
        self.lbl_current_file.pack(anchor=tk.W)

        self.lbl_stats = ttk.Label(info_frame, text="")
        self.lbl_stats.pack(anchor=tk.W)

        # 日志显示
        log_frame = ttk.LabelFrame(self.root, text="日志", padding=10)
        log_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

        self.log_text = tk.Text(log_frame, wrap=tk.WORD, state=tk.DISABLED)
        scrollbar = ttk.Scrollbar(log_frame, command=self.log_text.yview)
        self.log_text.configure(yscrollcommand=scrollbar.set)

        self.log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

'''

FileCleanerApp 类负责创建整个应用程序的界面和交互逻辑。在初始化方法 __init__ 中，我们设置了窗口的标题和大小，并初始化了多线程控制所需的 stop_event 和 message_queue。create_widgets 方法则创建了各种界面组件，包括顶部控制栏中的 “选择文件夹” 和 “停止处理” 按钮、进度条、实时信息面板以及日志显示区域。这些组件的布局和功能设置，为用户提供了一个直观且易于操作的交互界面。


多线程处理与消息队列
-----

'''
    def process_messages(self):
        try:
            while True:
                msg_type, msg_data = self.message_queue.get_nowait()
                if msg_type == 'progress':
                    self.update_progress(*msg_data)
                elif msg_type == 'log':
                    self.append_log(msg_data)
                elif msg_type =='stats':
                    self.show_stats(msg_data)
                elif msg_type == 'error':
                    self.show_error(msg_data)
        except Empty:
            pass
        finally:
            self.root.after(100, self.process_messages)
'''

为了避免阻塞主线程，影响用户界面的响应速度，我们使用多线程来处理文件的扫描和重复文件的查找。process_messages 方法负责从消息队列 message_queue 中获取消息，并根据消息类型调用相应的处理方法。例如，当接收到 'progress' 类型的消息时，会调用 update_progress 方法更新进度条和状态标签；接收到 'log' 类型的消息时，会调用 append_log 方法在日志显示区域添加新的日志信息。


文件处理与重复文件识别
-----

'''

    def process_folder(self, folder_path):
        try:
            start_time = datetime.now()
            self.message_queue.put(('log', f"开始处理文件夹：{folder_path}"))

            # 初始化目录结构
            duplicate_folder = os.path.abspath(os.path.join(folder_path, "重复文件"))
            os.makedirs(duplicate_folder, exist_ok=True)

            # 统计文件总数（排除重复文件夹）
            total_files = 0
            for root, dirs, files in os.walk(folder_path):
                # 排除重复文件夹
                dirs[:] = [d for d in dirs if os.path.abspath(os.path.join(root, d))!= duplicate_folder]
                total_files += len([f for f in files if os.path.splitext(f)[1].lower() in VALID_EXTENSIONS])

            if total_files == 0:
                self.message_queue.put(('error', "未找到符合条件的文件"))
                return

            # 初始化处理参数
            processed_files = 0
            hash_dict = {}
            file_info = []

            # 主处理循环
            for root, dirs, files in os.walk(folder_path):
                if self.stop_event.is_set():
                    break

                # 排除重复文件夹
                dirs[:] = [d for d in dirs if os.path.abspath(os.path.join(root, d))!= duplicate_folder]

                for file in files:
                    if self.stop_event.is_set():
                        break

                    ext = os.path.splitext(file)[1].lower()
                    if ext not in VALID_EXTENSIONS:
                        continue

                    file_path = os.path.join(root, file)
                    try:
                        # 更新进度
                        processed_files += 1
                        if processed_files % PROGRESS_INTERVAL == 0 or processed_files == total_files:
                            self.message_queue.put((
                                'progress',
                                (processed_files, total_files, file_path)
                            ))

                        # 计算哈希值
                        file_hash = calculate_file_hash(file_path)
                        if not file_hash:
                            continue

                        file_size = os.path.getsize(file_path)
                        file_info.append({
                            '序号': len(file_info) + 1,
                            '文件名': file,
                            '文件大小': file_size,
                            '哈希值': file_hash,
                            '路径': file_path
                        })

                        # 处理重复文件
                        if file_hash in hash_dict:
                            original_file = hash_dict[file_hash]
                            self.message_queue.put(('log',
                                                    f"发现重复文件：{file} -> 原始文件：{os.path.basename(original_file)}"
                                                    ))
                            safe_move_file(file_path, duplicate_folder)
                        else:
                            hash_dict[file_hash] = file_path

                    except Exception as e:
                        logging.error(f"处理文件失败：{file_path} - {str(e)}")
                        self.message_queue.put(('log', f"错误：{str(e)}"))

            # 生成报告
            if not self.stop_event.is_set():
                self.generate_report(duplicate_folder, file_info, start_time, hash_dict)

        except Exception as e:
            self.message_queue.put(('error', str(e)))
            logging.exception("处理过程中发生未捕获异常")
        finally:
            self.message_queue.put(('log', "处理完成"))
            self.running = False


'''

process_folder 方法是整个文件处理的核心部分。它首先创建 “重复文件” 文件夹，并统计指定文件夹及其子文件夹中符合条件的文件总数。然后，通过 os.walk 遍历文件系统，对每个符合条件的文件计算其哈希值，并将文件信息存储在 file_info 列表中。如果发现哈希值相同的文件，即认为是重复文件，将其移动到 “重复文件” 文件夹中。在处理过程中，会不断更新进度条，并将处理信息通过消息队列发送给主线程进行显示。


工具函数与文件操作
-----

'''
def safe_move_file(src, dest_folder):
    try:
        if not os.path.exists(dest_folder):
            os.makedirs(dest_folder, exist_ok=True)

        base_name = os.path.basename(src)
        dest_path = os.path.join(dest_folder, base_name)

        # 处理文件重名
        counter = 1
        name_parts = os.path.splitext(base_name)
        while os.path.exists(dest_path):
            new_name = f"{name_parts[0]}_({counter}){name_parts[1]}"
            dest_path = os.path.join(dest_folder, new_name)
            counter += 1

        shutil.move(src, dest_path)
        return True
    except Exception as e:
        logging.error(f"移动文件失败：{src} -> {dest_folder}: {str(e)}")
        return False


def get_human_size(size_bytes):
    units = ("B", "KB", "MB", "GB", "TB")
    if size_bytes == 0:
        return "0B"

    unit_index = 0
    size = float(size_bytes)
    while size >= 1024 and unit_index < len(units) - 1:
        size /= 1024
        unit_index += 1

    return f"{size:.2f} {units[unit_index]}"


def calculate_file_hash(file_path):
    sha256 = hashlib.sha256()
    try:
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256.update(chunk)
        return sha256.hexdigest()
    except Exception as e:
        logging.error(f"计算文件哈希失败：{file_path} - {str(e)}")
        return None

'''

这部分代码定义了几个工具函数，用于辅助文件操作。safe_move_file 函数负责将文件从源路径移动到目标文件夹，并自动处理文件名冲突的情况。get_human_size 函数将文件大小从字节转换为更易读的格式，如 KB、MB 等。calculate_file_hash 函数则使用 SHA - 256 算法计算文件的哈希值，通过读取文件内容的分块来更新哈希对象，从而得到文件的唯一哈希标识。

最后，在主程序入口处，创建 Tk 根窗口，实例化 FileCleanerApp 类，并启动主事件循环，使应用程序开始运行，等待用户的操作。

如图所示
-----

![](/img/文件筛选3.0.jpg)

